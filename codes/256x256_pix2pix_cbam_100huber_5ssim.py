# -*- coding: utf-8 -*-
"""256x256_pix2pix_CBAM_100huber_5SSIM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19sE0mBz2BeYhhS6Malxoqf4kBh1xMxNg
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/Data/Datasets.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/Data')

#pip install tensorflow-addons

import tensorflow as tf
#import tensorflow_addons as tfa
from tensorflow.keras.preprocessing import image
from tensorflow.keras.callbacks import EarlyStopping
import skimage
from skimage.metrics import structural_similarity as ssim
from skimage import measure
from PIL import Image
import cv2
import numpy as np
from numpy import asarray

import os
from os import listdir
import pathlib
import time
import datetime

import matplotlib.image as mpimg
from matplotlib import pyplot as plt
from IPython import display

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/256x256_pix2pix_CBAM_100huber_5SSIm'

PATH = '/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/Data/'

image_size = [256 ,256]

def load(image_file):
  # Read and decode an image file to a uint8 tensor
  image = tf.io.read_file(image_file)
  image = tf.io.decode_jpeg(image)

  # Split each image tensor into two tensors:
  # - one with a real building facade image
  # - one with an architecture label image
  w = tf.shape(image)[1]
  w = w // 2
  input_image = image[:, :w, :]
  real_image = image[:, w:, :]

  # Convert both images to float32 tensors
  input_image = tf.cast(input_image, tf.float32)
  real_image = tf.cast(real_image, tf.float32)

  if tf.shape(input_image)[0] > image_size[0]:
       # Resize both images to 256*256
    input_image = tf.image.resize(input_image, image_size,
                                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    real_image = tf.image.resize(real_image, image_size,
                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)



  return input_image, real_image

inp, re = load(PATH + '400_Train_49-01/img_110011.jpg')
# Casting to int for matplotlib to display the images
plt.figure()
plt.imshow(inp / 255.0)
plt.figure()
plt.imshow(re / 255.0)

# The facade training set consist of 400 images
BUFFER_SIZE = 100
# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment
BATCH_SIZE = 4
# Each image is 256x256 in size
IMG_WIDTH = image_size[1]
IMG_HEIGHT = image_size[0]

def resize(input_image, real_image, height, width):
  input_image = tf.image.resize(input_image, [height, width],
                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
  real_image = tf.image.resize(real_image, [height, width],
                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

  return input_image, real_image

def random_crop(input_image, real_image):
  stacked_image = tf.stack([input_image, real_image], axis=0)
  cropped_image = tf.image.random_crop(
      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])

  return cropped_image[0], cropped_image[1]

# Normalizing the images to [-1, 1]
def normalize(input_image, real_image):
  input_image = (input_image / 127.5) - 1
  real_image = (real_image / 127.5) - 1

  return input_image, real_image

@tf.function()
def random_jitter(input_image, real_image):

  rnd = tf.random.uniform(())

  if rnd < 0.5:
    # Random mirroring
    input_image = tf.image.flip_left_right(input_image)
    real_image = tf.image.flip_left_right(real_image)

  elif rnd > 0.7:
    input_image = tf.image.flip_up_down(input_image)
    real_image = tf.image.flip_up_down(real_image)

  else:
    input_image = input_image
    real_image = real_image

  return input_image, real_image

plt.figure(figsize=(6, 6))
for i in range(4):
  rj_inp, rj_re = random_jitter(inp, re)
  plt.subplot(2, 2, i + 1)
  plt.imshow(rj_inp / 255.0)
  plt.axis('off')
plt.show()

def load_image_train(image_file):
  input_image, real_image = load(image_file)
  input_image, real_image = random_jitter(input_image, real_image)
  input_image, real_image = normalize(input_image, real_image)

  return input_image, real_image

def load_image_test(image_file):
  input_image, real_image = load(image_file)
  input_image, real_image = resize(input_image, real_image,
                                   IMG_HEIGHT, IMG_WIDTH)
  input_image, real_image = normalize(input_image, real_image)

  return input_image, real_image

train_dataset = tf.data.Dataset.list_files(PATH + '400_Train_49-01/*.jpg')
train_dataset = train_dataset.map(load_image_train,
                                  num_parallel_calls=tf.data.AUTOTUNE)

train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.batch(BATCH_SIZE)

try:
  test_dataset = tf.data.Dataset.list_files(PATH + '49-01_merged/*.jpg')
except tf.errors.InvalidArgumentError:
  test_dataset = tf.data.Dataset.list_files(PATH + 'val/*.jpg')
test_dataset = test_dataset.map(load_image_test)
test_dataset = test_dataset.batch(BATCH_SIZE)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

def se_block(residual, name, ratio=8):
  """Contains the implementation of Squeeze-and-Excitation(SE) block.
  As described in https://arxiv.org/abs/1709.01507.
  """

  kernel_initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=2.0)
  bias_initializer = tf.compat.v1.constant_initializer(value=0.0)

  with tf.compat.v1.variable_scope(name):
    channel = residual.get_shape()[-1]
    # Global average pooling
    squeeze = tf.reduce_mean(input_tensor=residual, axis=[1,2], keepdims=True)
    assert squeeze.get_shape()[1:] == (1,1,channel)
    excitation = tf.compat.v1.layers.dense(inputs=squeeze,
                                 units=channel//ratio,
                                 activation=tf.nn.relu,
                                 kernel_initializer=kernel_initializer,
                                 bias_initializer=bias_initializer,
                                 name='bottleneck_fc')
    assert excitation.get_shape()[1:] == (1,1,channel//ratio)
    excitation = tf.compat.v1.layers.dense(inputs=excitation,
                                 units=channel,
                                 activation=tf.nn.sigmoid,
                                 kernel_initializer=kernel_initializer,
                                 bias_initializer=bias_initializer,
                                 name='recover_fc')
    assert excitation.get_shape()[1:] == (1,1,channel)
    # top = tf.multiply(bottom, se, name='scale')
    scale = residual * excitation
  return scale


def cbam_block(input_feature, name, ratio=8):
  """Contains the implementation of Convolutional Block Attention Module(CBAM) block.
  As described in https://arxiv.org/abs/1807.06521.
  """

  with tf.compat.v1.variable_scope(name):
    attention_feature = channel_attention(input_feature, 'ch_at', ratio)
    attention_feature = spatial_attention(attention_feature, 'sp_at')
    print ("CBAM Hello")
  return attention_feature

def channel_attention(input_feature, name, ratio=8):

  kernel_initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=2.0)
  bias_initializer = tf.compat.v1.constant_initializer(value=0.0)

  with tf.compat.v1.variable_scope(name):

    channel = input_feature.get_shape()[-1]
    avg_pool = tf.reduce_mean(input_tensor=input_feature, axis=[1,2], keepdims=True)
    #print(avg_pool.shape)

    assert avg_pool.get_shape()[1:] == (1,1,channel)
    avg_pool = tf.keras.layers.Dense(units=channel//ratio,
                                 activation=tf.nn.relu,
                                 kernel_initializer=kernel_initializer,
                                 bias_initializer=bias_initializer)(avg_pool) #,name='mlp_0'
    assert avg_pool.get_shape()[1:] == (1,1,channel//ratio)
    avg_pool = tf.keras.layers.Dense(
                                 units=channel,
                                 kernel_initializer=kernel_initializer,
                                 bias_initializer=bias_initializer)(avg_pool) #,name='mlp_1'
    assert avg_pool.get_shape()[1:] == (1,1,channel)

    max_pool = tf.reduce_max(input_tensor=input_feature, axis=[1,2], keepdims=True)
    assert max_pool.get_shape()[1:] == (1,1,channel)
    max_pool = tf.keras.layers.Dense(
                                 units=channel//ratio,
                                 activation=tf.nn.relu)(max_pool) #,name='mlp_2'
    assert max_pool.get_shape()[1:] == (1,1,channel//ratio)
    max_pool = tf.keras.layers.Dense(
                                 units=channel)(max_pool) #,name='mlp_3'
    assert max_pool.get_shape()[1:] == (1,1,channel)

    scale = tf.sigmoid(avg_pool + max_pool, 'sigmoid')

  return input_feature * scale

def spatial_attention(input_feature, name):
  kernel_size = 7
  kernel_initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=2.0)
  with tf.compat.v1.variable_scope(name):
    avg_pool = tf.reduce_mean(input_tensor=input_feature, axis=[3], keepdims=True)
    assert avg_pool.get_shape()[-1] == 1
    max_pool = tf.reduce_max(input_tensor=input_feature, axis=[3], keepdims=True)
    assert max_pool.get_shape()[-1] == 1
    concat = tf.concat([avg_pool,max_pool], 3)
    assert concat.get_shape()[-1] == 2

    concat = tf.keras.layers.Conv2D(
                              filters=1,
                              kernel_size=[kernel_size,kernel_size],
                              strides=[1,1],
                              padding="same",
                              activation=None,
                              kernel_initializer=kernel_initializer,
                              use_bias=False)(concat) #,name='conv'
    assert concat.get_shape()[-1] == 1
    concat = tf.sigmoid(concat, 'sigmoid')

  return input_feature * concat

OUTPUT_CHANNELS = 3

def Generator():

  inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])

  initializer = tf.random_normal_initializer(0., 0.02)
  down_01 = tf.keras.layers.Conv2D(64, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(inputs) #(batch_size, 128, 128, 64)
  down_01 = tf.keras.layers.LayerNormalization()(down_01)
  down_01 = tf.keras.layers.LeakyReLU()(down_01)
  cbam_01 = cbam_block(down_01, 'cbam_block_01')

  down_02 = tf.keras.layers.Conv2D(128, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_01) #(batch_size, 64, 64, 128)
  down_02 = tf.keras.layers.LayerNormalization()(down_02)
  down_02 = tf.keras.layers.LeakyReLU()(down_02)
  cbam_02 = cbam_block(down_02, 'cbam_block_02')

  down_03 = tf.keras.layers.Conv2D(256, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_02) #(batch_size, 32, 32, 256)
  down_03 = tf.keras.layers.LayerNormalization()(down_03)
  down_03 = tf.keras.layers.LeakyReLU()(down_03)
  cbam_03 = cbam_block(down_03, 'cbam_block_03')

  down_04 = tf.keras.layers.Conv2D(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_03) #(batch_size, 16, 16, 512)
  down_04 = tf.keras.layers.LayerNormalization()(down_04)
  down_04 = tf.keras.layers.LeakyReLU()(down_04)
  cbam_04 = cbam_block(down_04, 'cbam_block_04')

  down_05 = tf.keras.layers.Conv2D(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_04) #(batch_size, 8, 8, 512)
  down_05 = tf.keras.layers.LayerNormalization()(down_05)
  down_05 = tf.keras.layers.LeakyReLU()(down_05)
  cbam_05 = cbam_block(down_05, 'cbam_block_05')

  down_06 = tf.keras.layers.Conv2D(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_05) #(batch_size, 4, 4, 512)
  down_06 = tf.keras.layers.LayerNormalization()(down_06)
  down_06 = tf.keras.layers.LeakyReLU()(down_06)
  cbam_06 = cbam_block(down_06, 'cbam_block_06')

  down_07 = tf.keras.layers.Conv2D(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_06) #(batch_size, 2, 2, 512)
  down_07 = tf.keras.layers.LayerNormalization()(down_07)
  down_07 = tf.keras.layers.LeakyReLU()(down_07)
  cbam_07 = cbam_block(down_07, 'cbam_block_07')

  down_08 = tf.keras.layers.Conv2D(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_07) #(batch_size, 1, 1, 512)
  down_08 = tf.keras.layers.LayerNormalization()(down_08)
  down_08 = tf.keras.layers.LeakyReLU()(down_08)
  cbam_08 = cbam_block(down_08, 'cbam_block_08')

  up_01 = tf.keras.layers.Conv2DTranspose(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_08) #(batch_size, 2, 2, 1024)
  up_01 = tf.keras.layers.LayerNormalization()(up_01)
  up_01 = tf.keras.layers.ReLU()(up_01)
  concat_01 = tf.keras.layers.Concatenate()([up_01, down_07])
  cbam_09 = cbam_block(concat_01, 'cbam_block_09')

  up_02 = tf.keras.layers.Conv2DTranspose(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_09) #(batch_size, 4, 4, 1024)
  up_02 = tf.keras.layers.LayerNormalization()(up_02)
  up_02 = tf.keras.layers.ReLU()(up_02)
  concat_02 = tf.keras.layers.Concatenate()([up_02, down_06])
  cbam_10 = cbam_block(concat_02, 'cbam_block_10')

  up_03 = tf.keras.layers.Conv2DTranspose(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_10) #(batch_size, 8, 8, 1024)
  up_03 = tf.keras.layers.LayerNormalization()(up_03)
  up_03 = tf.keras.layers.ReLU()(up_03)
  concat_03 = tf.keras.layers.Concatenate()([up_03, down_05])
  cbam_11 = cbam_block(concat_03, 'cbam_block_11')

  up_04 = tf.keras.layers.Conv2DTranspose(512, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_11) #(batch_size, 16, 16, 1024)
  up_04 = tf.keras.layers.LayerNormalization()(up_04)
  up_04 = tf.keras.layers.ReLU()(up_04)
  concat_04 = tf.keras.layers.Concatenate()([up_04, down_04])
  cbam_12 = cbam_block(concat_04, 'cbam_block_12')

  up_05 = tf.keras.layers.Conv2DTranspose(256, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_12) #(batch_size, 32, 32, 512)
  up_05 = tf.keras.layers.LayerNormalization()(up_05)
  up_05 = tf.keras.layers.ReLU()(up_05)
  concat_05 = tf.keras.layers.Concatenate()([up_05, down_03])
  cbam_13 = cbam_block(concat_05, 'cbam_block_13')

  up_06 = tf.keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_13) #(batch_size, 64, 64, 256)
  up_06 = tf.keras.layers.LayerNormalization()(up_06)
  up_06 = tf.keras.layers.ReLU()(up_06)
  concat_06 = tf.keras.layers.Concatenate()([up_06, down_02])
  cbam_14 = cbam_block(concat_06, 'cbam_block_14')

  up_07 = tf.keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(cbam_14) #(batch_size, 128, 128, 256)
  up_07 = tf.keras.layers.LayerNormalization()(up_07)
  up_07 = tf.keras.layers.ReLU()(up_07)
  concat_07 = tf.keras.layers.Concatenate()([up_07, down_01])


  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,
                                         strides=2,
                                         padding='same',
                                         kernel_initializer=initializer,
                                         activation='tanh')(concat_07)  # (batch_size, 256, 256, 3)



  return tf.keras.Model(inputs=inputs, outputs=last)

generator = Generator()
tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)

gen_output = generator(inp[tf.newaxis, ...], training=False)
plt.imshow(gen_output[0, ...])

LAMBDA1 = 100
LAMBDA2 = 5

loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target):
  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)

  # Smooth L1 loss
  Huber_loss = tf.keras.losses.Huber(delta=0.5)
  huber_loss = Huber_loss(target, gen_output)

  # SSIM loss
  ssim = tf.reduce_mean(tf.image.ssim(target, gen_output, 2.0))
  ssim_loss = 1 - ssim


  total_gen_loss = gan_loss + (LAMBDA1 * huber_loss) + (LAMBDA2 * ssim_loss)

  return total_gen_loss, gan_loss, huber_loss, ssim_loss

def downsample(filters, size, apply_norm=True):
  initializer = tf.random_normal_initializer(0., 0.02)

  result = tf.keras.Sequential()
  result.add(
      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', use_bias=False, kernel_initializer=initializer))

  if apply_norm:
    result.add(tf.keras.layers.LayerNormalization())

  result.add(tf.keras.layers.LeakyReLU())

  return result

def Discriminator():
  initializer = tf.random_normal_initializer(0., 0.02)

  inp = tf.keras.layers.Input(shape=[image_size[0], image_size[1], 3], name='input_image')
  tar = tf.keras.layers.Input(shape=[image_size[0], image_size[1], 3], name='target_image')

  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)

  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)
  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)
  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)

  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)
  conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                kernel_initializer=initializer,
                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)

  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)

  last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)

  return tf.keras.Model(inputs=[inp, tar], outputs=last)

discriminator = Discriminator()
tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)

disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)
plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')
plt.colorbar()

def discriminator_loss(disc_real_output, disc_generated_output):
  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)

  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)

  total_disc_loss = real_loss + generated_loss

  return total_disc_loss

from tensorflow.keras.optimizers import Adam

generator_optimizer = tf.keras.optimizers.legacy.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.legacy.Adam(2e-4, beta_1=0.5)

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

def generate_images(model, test_input, tar):
  prediction = model(test_input, training=True)
  plt.figure(figsize=(15, 15))

  display_list = [test_input[0], tar[0], prediction[0]]
  title = ['Input Image', 'Ground Truth', 'Predicted Image']

  for i in range(3):
    plt.subplot(1, 3, i+1)
    plt.title(title[i])
    # Getting the pixel values in the [0, 1] range to plot.
    plt.imshow(display_list[i] * 0.5 + 0.5)
    plt.axis('off')
  plt.show()
  return prediction, tar

from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()

for example_input, example_target in test_dataset.take(1):

  img_pred, tar = generate_images(generator, example_input, example_target)
  #mse = tf.losses.mean_squared_error(tar[0], img_pred[0])
  #print('MSE', mse)
  tar = tar[0]
  img_pred = img_pred[0]
  tar = np.asfarray(tar)
  img_pred = np.asfarray(img_pred)
  ssim = skimage.metrics.structural_similarity(tar, img_pred, multichannel=True)
  mse = skimage.metrics.mean_squared_error(tar, img_pred)
  print('SSIM:', ssim)
  print('MSE:', mse)

current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
train_log_dir = 'logs/gradient_tape/' + current_time + '/train'
test_log_dir = 'logs/gradient_tape/' + current_time + '/test'
train_summary_writer = tf.summary.create_file_writer(train_log_dir)
test_summary_writer = tf.summary.create_file_writer(test_log_dir)

@tf.function
def train_step(input_image, target):
  gp_weight = 10.0
  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    gen_output = generator(input_image, training=True)

    disc_real_output = discriminator([input_image, target], training=True)
    disc_generated_output = discriminator([input_image, gen_output], training=True)

    gen_total_loss, gen_gan_loss, gen_huber_loss, gen_ssim_loss = generator_loss(disc_generated_output, gen_output, target)
    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)



  generator_gradients = gen_tape.gradient(gen_total_loss,
                                          generator.trainable_variables)
  discriminator_gradients = disc_tape.gradient(disc_loss,
                                               discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(generator_gradients,
                                          generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                              discriminator.trainable_variables))

  """
    with train_summary_writer.as_default():
      tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)
      tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)
      tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)
      tf.summary.scalar('gen_mse_loss', gen_mse_loss, step=step//1000)
      tf.summary.scalar('gen_ssim_loss', gen_ssim_loss, step=step//1000)
      tf.summary.scalar('disc_loss', disc_loss, step=step//1000)
  """
  return gen_total_loss, gen_gan_loss, gen_huber_loss,  gen_ssim_loss, disc_loss

@tf.function
def test_step(input_image, target):

  gen_output = generator(input_image)

  disc_real_output = discriminator([input_image, target])
  disc_generated_output = discriminator([input_image, gen_output])

  gen_total_loss, gen_gan_loss, gen_huber_loss, gen_ssim_loss = generator_loss(disc_generated_output, gen_output, target)
  disc_loss = discriminator_loss(disc_real_output, disc_generated_output)
  """
    with test_summary_writer.as_default():
      tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)
      tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)
      tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)
      tf.summary.scalar('gen_mse_loss', gen_mse_loss, step=step//1000)
      tf.summary.scalar('gen_ssim_loss', gen_ssim_loss, step=step//1000)
      tf.summary.scalar('disc_loss', disc_loss, step=step//1000)
  """
  return gen_total_loss, gen_gan_loss, gen_huber_loss, gen_ssim_loss, disc_loss

def custom_ssim(input_image, target_image):
  C1 = 0.00
  C2 = 0.00
  if len(input_image.shape) <= 3:
    print("Input images converted to Tensors.")
    input_image = tf.expand_dims(input_image, axis=0)
    target_image = tf.expand_dims(target_image, axis=0)

  no = input_image.shape[0]
  ssim = []
  for i in range(no):
    XX = input_image[i, :, :, :]
    XX = tf.reshape(XX, [-1])
    mu1 = tf.reduce_mean( XX / tf.reduce_max(XX) )
    mu2 = tf.reduce_mean(target_image)
    var1 = tf.math.reduce_variance(XX / tf.reduce_max(XX))
    var2 = tf.math.reduce_variance(target_image)
    cov = np.cov((np.reshape(input_image.numpy(), -1), np.reshape(target_image.numpy(), -1)))
    cov12 = cov[0,1]
    ssim = ((2 * mu1 * mu2 + C1) * (2 * cov12 + C2)) / ((mu1 ** 2 + mu2 ** 2 + C1) * (var1 + var2 + C2))
  return ssim

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir {'logs/gradient_tape'}

EPOCHS = 400
img09_inp, img09_tar = load("/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/Data/53-03_merged/0009.jpg")
img09_inp, img09_tar = resize(img09_inp, img09_tar, IMG_HEIGHT, IMG_WIDTH)
img09_inp, img09_tar = normalize(img09_inp, img09_tar)
img09_input = tf.expand_dims(img09_inp, axis=0)
img09_target = tf.expand_dims(img09_tar, axis=0)

img09_pred, img09_tar = generate_images(generator, img09_input, img09_target)

img09_tar = img09_tar[0]
img09_pred = img09_pred[0]
img09_tar = np.asfarray(img09_tar)
img09_pred = np.asfarray(img09_pred)
ssim1 = custom_ssim(img09_input, img09_target)
ssim2 = tf.reduce_mean(tf.image.ssim(img09_input, img09_target, 1.))
mse = skimage.metrics.mean_squared_error(img09_tar, img09_pred)
print('CustomSSIM:', ssim1)
print('tfSSIM:', ssim2)
print('MSE:', mse)

img43_inp, img43_tar = load("/content/drive/MyDrive/ColabNotebooks/WSI/WSI/Codes/Data/53-03_merged/0043.jpg")
img43_inp, img43_tar = resize(img43_inp, img43_tar, IMG_HEIGHT, IMG_WIDTH)
img43_inp, img43_tar = normalize(img43_inp, img43_tar)
img43_input = tf.expand_dims(img43_inp, axis=0)
img43_target = tf.expand_dims(img43_tar, axis=0)

img43_pred, img43_tar = generate_images(generator, img43_input, img43_target)

img43_tar = img43_tar[0]
img43_pred = img43_pred[0]
img43_tar = np.asfarray(img43_tar)
img43_pred = np.asfarray(img43_pred)
ssim1 = custom_ssim(img43_input, img43_target)
ssim2 = tf.reduce_mean(tf.image.ssim(img43_input, img43_target, 1.))
mse = skimage.metrics.mean_squared_error(img43_tar, img43_pred)
print('customSSIM:', ssim1)
print('tfSSIM:', ssim2)
print('MSE:', mse)

for epoch in range(EPOCHS):
  start = time.time()
  display.clear_output(wait=True)
  for (train_input_image, train_target) in train_dataset:
    gen_total_train_loss, gen_gan_train_loss, gen_smoothL1_train_loss, gen_ssim_train_loss, disc_train_loss = train_step(train_input_image, train_target)

  with train_summary_writer.as_default():
    tf.summary.scalar('gen_total_loss',  gen_total_train_loss, step=epoch)
    tf.summary.scalar('gen_gan_loss',   gen_gan_train_loss, step=epoch)
    tf.summary.scalar('gen_SmoothL1_loss',  gen_smoothL1_train_loss, step=epoch)
    tf.summary.scalar('gen_ssim_loss',  gen_ssim_train_loss, step=epoch)
    tf.summary.scalar('disc_loss', disc_train_loss, step=epoch)

  for (test_input_image, test_target) in test_dataset:
    gen_total_test_loss, gen_gan_test_loss, gen_smoothL1_test_loss, gen_ssim_test_loss, disc_test_loss = test_step(test_input_image, test_target)

  with test_summary_writer.as_default():
    tf.summary.scalar('gen_total_loss',  gen_total_test_loss, step=epoch)
    tf.summary.scalar('gen_gan_loss',   gen_gan_test_loss, step=epoch)
    tf.summary.scalar('gen_smoothL1_loss',  gen_smoothL1_test_loss, step=epoch)
    tf.summary.scalar('gen_ssim_loss',  gen_ssim_test_loss, step=epoch)
    tf.summary.scalar('disc_loss', disc_test_loss, step=epoch)

  print('time:', time.time() - start)
  img09_pred, img09_tar = generate_images(generator, img09_input, img09_target)

  img09_tar = img09_tar[0]
  img09_pred = img09_pred[0]
  img09_tar = np.asfarray(img09_tar)
  img09_pred = np.asfarray(img09_pred)
  ssim1 = custom_ssim(img09_pred, img09_tar)
  ssim2 = tf.reduce_mean(tf.image.ssim(img09_pred, img09_tar, 1.))
  mse = skimage.metrics.mean_squared_error(img09_tar, img09_pred)
  print('customSSIM:', ssim1)
  print('tfSSIM:', ssim2)
  print('MSE:', mse)

  img43_pred, img43_tar = generate_images(generator, img43_input, img43_target)

  img43_tar = img43_tar[0]
  img43_pred = img43_pred[0]
  img43_tar = np.asfarray(img43_tar)
  img43_pred = np.asfarray(img43_pred)
  ssim1 = custom_ssim(img43_pred, img43_tar)
  ssim2 = tf.reduce_mean(tf.image.ssim(img43_pred, img43_tar, 1.))
  mse = skimage.metrics.mean_squared_error(img43_tar, img43_pred)
  print('customSSIM:', ssim1)
  print('tfSSIM:', ssim2)
  print('MSE:', mse)

  template = 'Epoch {}, gen_total_train_loss: {}, gen_gan_train_loss: {}, gen_smoothL1_train_loss: {}, gen_ssim_train_loss: {}, gen_total_test_loss: {}, gen_gan_test_loss: {}, gen_smoothL1_test_loss: {}, gen_ssim_test_loss: {}'

  print (template.format(epoch,
                         gen_total_train_loss,
                         gen_gan_train_loss,
                         gen_smoothL1_train_loss,
                         gen_ssim_train_loss,
                         gen_total_test_loss,
                         gen_gan_test_loss,
                         gen_smoothL1_test_loss,
                         gen_ssim_test_loss))


  checkpoint.save(file_prefix=checkpoint_prefix)

EPOCHS = 400
for example_input, example_target in test_dataset.take(1):
  img_pred, tar = generate_images(generator, example_input, example_target)

  tar = tar[0]
  img_pred = img_pred[0]
  tar = np.asfarray(tar)
  img_pred = np.asfarray(img_pred)
  ssim = skimage.metrics.structural_similarity(tar, img_pred, multichannel=True)
  mse = skimage.metrics.mean_squared_error(tar, img_pred)
  print('SSIM:', ssim)
  print('MSE:', mse)

for epoch in range(EPOCHS):
  start = time.time()

  display.clear_output(wait=True)


  for (train_input_image, train_target) in train_dataset:
    gen_total_train_loss, gen_gan_train_loss, gen_huber_train_loss, gen_ssim_train_loss, disc_train_loss = train_step(train_input_image, train_target)

  with train_summary_writer.as_default():
    tf.summary.scalar('gen_total_loss',  gen_total_train_loss, step=epoch)
    tf.summary.scalar('gen_gan_loss',   gen_gan_train_loss, step=epoch)
    tf.summary.scalar('gen_huber_loss',  gen_huber_train_loss, step=epoch)
    tf.summary.scalar('gen_ssim_loss',  gen_ssim_train_loss, step=epoch)
    tf.summary.scalar('disc_loss', disc_train_loss, step=epoch)

  for (test_input_image, test_target) in test_dataset:
    gen_total_test_loss, gen_gan_test_loss, gen_huber_test_loss, gen_ssim_test_loss, disc_test_loss = test_step(test_input_image, test_target)

  with test_summary_writer.as_default():
    tf.summary.scalar('gen_total_loss',  gen_total_test_loss, step=epoch)
    tf.summary.scalar('gen_gan_loss',   gen_gan_test_loss, step=epoch)
    tf.summary.scalar('gen_huber_loss',  gen_huber_test_loss, step=epoch)
    tf.summary.scalar('gen_ssim_loss',  gen_ssim_test_loss, step=epoch)
    tf.summary.scalar('disc_loss', disc_test_loss, step=epoch)

  print('time:', time.time() - start)
  img_pred, tar = generate_images(generator, example_input, example_target)

  tar = tar[0]
  img_pred = img_pred[0]
  tar = np.asfarray(tar)
  img_pred = np.asfarray(img_pred)
  ssim = skimage.metrics.structural_similarity(tar, img_pred, multichannel=True)
  mse = skimage.metrics.mean_squared_error(tar, img_pred)
  print('SSIM:', ssim)
  print('MSE:', mse)


  template = 'Epoch {}, gen_total_train_loss: {}, gen_gan_train_loss: {}, gen_huber_train_loss: {}, gen_ssim_train_loss:{}, gen_total_test_loss: {}, gen_gan_test_loss: {}, gen_huber_test_loss: {}, gen_ssim_test_loss:{}'

  print (template.format(epoch+1,
                         gen_total_train_loss,
                         gen_gan_train_loss,
                         gen_huber_train_loss,
                         gen_ssim_train_loss,
                         gen_total_test_loss,
                         gen_gan_test_loss,
                         gen_huber_test_loss,
                         gen_ssim_test_loss))


  checkpoint.save(file_prefix=checkpoint_prefix)

!tensorboard dev upload --logdir {'logs/gradient_tape'}

checkpoint_dir = './training_checkpoints'

!ls {checkpoint_dir}

# Restoring the latest checkpoint in checkpoint_dir
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
#checkpoint.restore(checkpoint_dir + '/ckpt-27')

"""FID Score"""

'''
From https://github.com/tsc2017/Frechet-Inception-Distance
Code derived from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py
Usage:
    Call get_fid(images1, images2)
Args:
    images1, images2: Numpy arrays with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary.
    dtype of the images is recommended to be np.uint8 to save CPU memory.
Returns:
    Frechet Inception Distance between the two image distributions.
'''

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import os
import functools
import numpy as np
import time
from tensorflow.python.ops import array_ops
# pip install tensorflow-gan
import tensorflow_gan as tfgan

session=tf.compat.v1.InteractiveSession()
# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown
BATCH_SIZE = 64

# Run images through Inception.
inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')
activations1 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations1')
activations2 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations2')
fcd = tfgan.eval.frechet_classifier_distance_from_activations(activations1, activations2)

INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'
INCEPTION_FINAL_POOL = 'pool_3'

def inception_activations(images = inception_images, num_splits = 1):
    images = tf.transpose(images, [0, 2, 3, 1])
    size = 299
    images = tf.compat.v1.image.resize_bilinear(images, [size, size])
    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)
    activations = tf.map_fn(
        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_FINAL_POOL, True),
        elems = array_ops.stack(generated_images_list),
        parallel_iterations = 1,
        back_prop = False,
        swap_memory = True,
        name = 'RunClassifier')
    activations = array_ops.concat(array_ops.unstack(activations), 0)
    return activations

activations =inception_activations()

def get_inception_activations(inps):
    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))
    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)
    for i in range(n_batches):
        inp = inps[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] / 255. * 2 - 1
        act[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(activations, feed_dict = {inception_images: inp})
    return act

def activations2distance(act1, act2):
    return session.run(fcd, feed_dict = {activations1: act1, activations2: act2})

def get_fid(images1, images2):
    session=tf.get_default_session()
    assert(type(images1) == np.ndarray)
    assert(len(images1.shape) == 4)
    assert(images1.shape[1] == 3)
    assert(np.min(images1[0]) >= 0 and np.max(images1[0]) > 10), 'Image values should be in the range [0, 255]'
    assert(type(images2) == np.ndarray)
    assert(len(images2.shape) == 4)
    assert(images2.shape[1] == 3)
    assert(np.min(images2[0]) >= 0 and np.max(images2[0]) > 10), 'Image values should be in the range [0, 255]'
    assert(images1.shape == images2.shape), 'The two numpy arrays must have the same shape'
    print('Calculating FID with %i images from each distribution' % (images1.shape[0]))
    start_time = time.time()
    act1 = get_inception_activations(images1)
    act2 = get_inception_activations(images2)
    fid = activations2distance(act1, act2)
    print('FID calculation time: %f s' % (time.time() - start_time))
    return fid

test_mse_val = []
test_ssim_val = []
test_psnr = []
test_fid = []
test_entropy = []
test_correction_score = []

# Run the trained model on a few examples from the test set
i = 0
for inp, tar in train_dataset.take(10):
  i+=1
  result = generate_images(generator, inp, tar)
  #image.save_img(f'predicted_test_{i}_img.jpg', result[0][0])
  result0 = result[0][0]
  result1 = result[1][0]
  result0 = np.asfarray(result0)
  result1 = np.asfarray(result1)
  ssim = skimage.metrics.structural_similarity(result0, result1, multichannel=True)
  mse = skimage.metrics.mean_squared_error(result0, result1)

  ref_target = tf.squeeze(tar)
  ref_inp = tf.squeeze(inp)

  n_target = 127.5*(ref_target + 1)
  n_inp = 127.5*(ref_inp + 1)
  #similarity_score, out_1, out_2 = haar_psi(n_target, n_inp)
  test_ssim_val.append(ssim)
  test_mse_val.append(mse)
  #test_haarpsi_val.append(similarity_score)
  #mse = np.square(np.subtract(result[0],result[1])).mean()
  print('SSIM:', ssim, 'MSE:', mse)
  #return ssim(result0, result1, multichannel=True), skimage.metrics.mean_squared_error(result0, result1)
  #print('SSIM:', ssim)
  #print('MSE:', mse)

import os, os.path
test_list = sorted(os.listdir(PATH+'test2'))
for i in range(len(test_list)):

  inp, tar = load_image_test(PATH+'test2/'+str(test_list[i]))
  inp = tf.expand_dims(inp, axis=0)
  tar = tf.expand_dims(tar, axis=0)
  result = generate_images(generator, inp, tar)
  #result0 = result[0][0]
  #result1 = result[1][0]
  result0 = np.asfarray(tf.squeeze(result[0]))
  result1 = np.asfarray(tf.squeeze(result[1]))

  ssim = skimage.metrics.structural_similarity(result0, result1, multichannel=True)
  mse = skimage.metrics.mean_squared_error(result0, result1)
  psnr = tf.image.psnr(inp, tar, max_val=1.0)
  #fid = get_fid(inp, tar)

  tf.keras.preprocessing.image.save_img(f'predicted_test_{i}_img.jpg', tf.squeeze(result[0]))
  test_psnr.append(psnr)
  #test_fid.append(fid)
  test_ssim_val.append(ssim)
  test_mse_val.append(mse)


  print('SSIM:', ssim, 'MSE:', mse)

